{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o8vuKPT6tRTD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from random import random\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P4PAT1gtRTD"
      },
      "source": [
        "# Augmentation operations and list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ACY6bkltRTE"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 32\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  return float(level) * maxval / 10.\n",
        "\n",
        "def sample_level(n):\n",
        "  return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "def vipaug_g_prep(img, _):\n",
        "        kernel = 2 #cifar is 2, imagenet is dunno\n",
        "        vital = 0.001 #cifar10: 0.001, cifar100: 0.005, imagenet:  0.001\n",
        "        nonvital = 0.014 #cifar10: 0.014, cifar100: 0.012, imagenet:  0.005\n",
        "        fft = np.fft.fftn(img)\n",
        "        absolute = np.abs(fft)\n",
        "        noise_phase = np.zeros((np.shape(img)[0],np.shape(img)[1],np.shape(img)[2]))\n",
        "        # kernel filter\n",
        "        for p in range(3):\n",
        "            index_list = []\n",
        "            for i in range(len(absolute[:,:,p])//kernel):\n",
        "                for j in range(len(absolute[:,:,p])//kernel):\n",
        "                    number_list = []\n",
        "\n",
        "                    for k2 in range(kernel):\n",
        "                        for k1 in range(kernel):\n",
        "                            number_list.append(absolute[:,:,p][kernel*i + k2, kernel*j + k1])\n",
        "\n",
        "                    index = number_list.index(max(number_list))\n",
        "                    k3 = index // kernel\n",
        "                    k4 = index % kernel\n",
        "\n",
        "                    #save index\n",
        "                    index_x = kernel*i + k3\n",
        "                    index_y = kernel*j + k4\n",
        "                    index_list.append(np.array([index_x,index_y]))\n",
        "\n",
        "            #make ones matrix\n",
        "            mask = np.ones((np.shape(img)[0],np.shape(img)[1]))\n",
        "            #make masked matrix\n",
        "            for i1 in range(len(index_list)):\n",
        "                mask[index_list[i1][0],index_list[i1][1]] = 0\n",
        "\n",
        "            #add gaussian noise at phase\n",
        "            mask_vital = mask - np.ones((np.shape(img)[0],np.shape(img)[1]))\n",
        "            mask_vital = mask_vital * (-1)\n",
        "\n",
        "            gaussian_noise_vital = np.random.normal(0,vital**0.5,(np.shape(img)[0],np.shape(img)[1]))\n",
        "            gaussian_noise = np.random.normal(0,nonvital**0.5,(np.shape(img)[0],np.shape(img)[1]))\n",
        "            masked_gaussian_noise = mask * gaussian_noise\n",
        "\n",
        "            masked_gaussian_noise_vital = mask_vital * gaussian_noise_vital\n",
        "            noise_phase[:,:,p] = np.angle(fft[:,:,p]) + masked_gaussian_noise + masked_gaussian_noise_vital\n",
        "\n",
        "        return noise_phase\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "  return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "  return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 4)\n",
        "  return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "  degrees = int_parameter(sample_level(level), 30)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    degrees = -degrees\n",
        "  return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 256)\n",
        "  return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def color(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def contrast(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def brightness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def sharpness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "def nothing(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return pil_img\n",
        "\n",
        "def vipaug_g(x, _):\n",
        "        op = np.random.choice(augmentations_vipaug_list)\n",
        "        # print(\"first:\", op)\n",
        "        fft_before = np.fft.fftn(x)\n",
        "        x = op(x, 3)\n",
        "\n",
        "        x_aug = x.copy()\n",
        "        op = np.random.choice(augmentations_vipaug_list)\n",
        "        # print(\"second:\",op)\n",
        "        x_aug = op(x_aug, 3)\n",
        "\n",
        "        x = np.array(x).astype(np.uint8)\n",
        "        x_aug = np.array(x_aug).astype(np.uint8)\n",
        "\n",
        "        fft_1 = np.fft.fftn(x)\n",
        "\n",
        "        fft_2 = np.fft.fftn(x_aug)\n",
        "        # print(\"Difference between fft_1 and fft_2 (after phase swap):\", np.abs(fft_1 - fft_2).mean())\n",
        "\n",
        "        p = random.uniform(0, 1)\n",
        "        if p > 0.5: #VIPAug-G probability\n",
        "            # print(\"first pass!\", p)\n",
        "            abs_1, angle_1 = np.abs(fft_1), np.angle(fft_1)\n",
        "            abs_2, angle_2 = np.abs(fft_2), np.angle(fft_2)\n",
        "\n",
        "            fft_1 = abs_1*np.exp((1j) * angle_2)\n",
        "            fft_2 = abs_2*np.exp((1j) * angle_1)\n",
        "            # print(\"First pass fft_1 and fft_2:\", np.abs(fft_1 - fft_2).mean())\n",
        "\n",
        "            p = random.uniform(0, 1)\n",
        "            # print(\"in first pass\", p)\n",
        "\n",
        "            if p > 0.5:\n",
        "                x = np.fft.ifftn(fft_1)\n",
        "            else:\n",
        "                x = np.fft.ifftn(fft_2)\n",
        "\n",
        "        else:\n",
        "            p = random.uniform(0, 1)\n",
        "            # print(\"second pass!\", p)\n",
        "            if p > 0.5:\n",
        "                # print(\"third pass!\", p)\n",
        "                angle_2 = vipaug_g_prep(x_aug, _)\n",
        "                fft_1 = np.abs(fft_1)*np.exp((1j) * angle_2)\n",
        "                x = np.fft.ifftn(fft_1)\n",
        "            else:\n",
        "                # print(\"fourth pass!\", p)\n",
        "                angle_1 = vipaug_g_prep(x, _)\n",
        "                fft_2 = np.abs(fft_2)*np.exp((1j) * angle_1)\n",
        "                x = np.fft.ifftn(fft_2)\n",
        "\n",
        "        x = np.real(x)\n",
        "        x = np.clip(x, 0, 255).astype(np.uint8)\n",
        "\n",
        "        return Image.fromarray(x)\n",
        "\n",
        "augmentations_vipaug_list = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y]\n",
        "\n",
        "augmentations = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, vipaug_g]\n",
        "\n",
        "augmentations_all = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, vipaug_g, color, contrast, brightness, sharpness]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGotXGJ-UnIS",
        "outputId": "38976ce8-0ade-4216-9e29-c3903a185ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "depth: 1\n",
            "aug combinations: <function vipaug_g at 0x149da43a0>\n",
            "first: <function shear_x at 0x13a2513a0>\n",
            "second: <function solarize at 0x13fb8e670>\n",
            "depth: 1\n",
            "aug combinations: <function equalize at 0x13a1f64c0>\n",
            "depth: 3\n",
            "aug combinations: <function shear_x at 0x13a2513a0>\n",
            "aug combinations: <function solarize at 0x13fb8e670>\n",
            "aug combinations: <function autocontrast at 0x13a123310>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image, label = train_data[11]\n",
        "augie_mage = aug(image, preprocess)\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-1.0, -1.0, -1.0],\n",
        "    std=[2.0, 2.0, 2.0]\n",
        ")\n",
        "augie_mage = inv_normalize(augie_mage).clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy()\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "ax1.imshow(image)\n",
        "ax1.set_title(\"Original\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(augie_mage)\n",
        "ax2.set_title(\"VipAug\")\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYm0Jy-vtRTE",
        "outputId": "47e4c94b-a3c9-445a-8704-e172325a34be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image, label = train_data[10]\n",
        "aug_image = aug(image, preprocess)\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-1.0, -1.0, -1.0],\n",
        "    std=[2.0, 2.0, 2.0]\n",
        ")\n",
        "\n",
        "# Undo normalization and convert to numpy\n",
        "aug_image = inv_normalize(aug_image).clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "ax1.imshow(image)\n",
        "ax1.set_title(\"Original\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(aug_image)\n",
        "ax2.set_title(\"Autocontrast\")\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2yA1XZmtRTE"
      },
      "source": [
        "# Mix augmentations final image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L6nmQPgKtRTE"
      },
      "outputs": [],
      "source": [
        "def aug(image, preprocess):\n",
        "  \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "\n",
        "  Args:\n",
        "    image: PIL.Image input image\n",
        "    preprocess: Preprocessing function which should return a torch tensor.\n",
        "\n",
        "  Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "  \"\"\"\n",
        "  aug_list = augmentations\n",
        "\n",
        "  ws = np.float32(np.random.dirichlet([1] * 3))\n",
        "  m = np.float32(np.random.beta(1, 1))\n",
        "\n",
        "  mix = torch.zeros_like(preprocess(image))\n",
        "  for i in range(3):\n",
        "    image_aug = image.copy()\n",
        "    depth = -1 if -1 > 0 else np.random.randint(\n",
        "        1, 4)\n",
        "    # print(\"depth:\", depth)\n",
        "    for _ in range(depth):\n",
        "      op = np.random.choice(aug_list)\n",
        "      # print(\"aug combinations:\", op)\n",
        "      image_aug = op(image_aug, 3)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * preprocess(image_aug)\n",
        "\n",
        "  mixed = (1 - m) * preprocess(image) + m * mix\n",
        "  return mixed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdpEmxdbtRTF"
      },
      "source": [
        "# Make Dataset out of augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7wU4USustRTF"
      },
      "outputs": [],
      "source": [
        "class AugMixDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"Dataset wrapper to perform AugMix augmentation.\"\"\"\n",
        "\n",
        "  def __init__(self, dataset, preprocess, no_jsd=True):\n",
        "    self.dataset = dataset\n",
        "    self.preprocess = preprocess\n",
        "    self.no_jsd = no_jsd\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.dataset[i]\n",
        "    if self.no_jsd:\n",
        "      return aug(x, self.preprocess), y\n",
        "    else:\n",
        "      im_tuple = (self.preprocess(x), aug(x, self.preprocess),\n",
        "                  aug(x, self.preprocess))\n",
        "      return im_tuple, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv3GkpoItRTF"
      },
      "source": [
        "# Training and Test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XBrq7-NstRTF"
      },
      "outputs": [],
      "source": [
        "def train(net, train_loader, optimizer, scheduler, no_jsd=True, print_freq=100):\n",
        "  \"\"\"Train for one epoch.\"\"\"\n",
        "  net.train()\n",
        "  loss_ema = 0.\n",
        "  for i, (images, targets) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if no_jsd:\n",
        "      images = images.cuda()\n",
        "      targets = targets.cuda()\n",
        "      logits = net(images)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    else:\n",
        "      images_all = torch.cat(images, 0).cuda()\n",
        "      targets = targets.cuda()\n",
        "      logits_all = net(images_all)\n",
        "      logits_clean, logits_aug1, logits_aug2 = torch.split(\n",
        "          logits_all, images[0].size(0))\n",
        "\n",
        "      # Cross-entropy is only computed on clean images\n",
        "      loss = F.cross_entropy(logits_clean, targets)\n",
        "\n",
        "      p_clean, p_aug1, p_aug2 = F.softmax(\n",
        "          logits_clean, dim=1), F.softmax(\n",
        "              logits_aug1, dim=1), F.softmax(\n",
        "                  logits_aug2, dim=1)\n",
        "\n",
        "      # Clamp mixture distribution to avoid exploding KL divergence\n",
        "      p_mixture = torch.clamp((p_clean + p_aug1 + p_aug2) / 3., 1e-7, 1).log()\n",
        "      loss += 12 * (F.kl_div(p_mixture, p_clean, reduction='batchmean') +\n",
        "                    F.kl_div(p_mixture, p_aug1, reduction='batchmean') +\n",
        "                    F.kl_div(p_mixture, p_aug2, reduction='batchmean')) / 3.\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    loss_ema = loss_ema * 0.9 + float(loss) * 0.1\n",
        "    if i % args.print_freq == 0:\n",
        "      print('Train Loss {:.3f}'.format(loss_ema))\n",
        "\n",
        "  return loss_ema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EBsCYDIMtRTF"
      },
      "outputs": [],
      "source": [
        "def test(net, test_loader):\n",
        "  \"\"\"Evaluate network on given dataset.\"\"\"\n",
        "  net.eval()\n",
        "  total_loss = 0.\n",
        "  total_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for images, targets in test_loader:\n",
        "      images, targets = images.cuda(), targets.cuda()\n",
        "      logits = net(images)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "      pred = logits.data.max(1)[1]\n",
        "      total_loss += float(loss.data)\n",
        "      total_correct += pred.eq(targets.data).sum().item()\n",
        "\n",
        "  return total_loss / len(test_loader.dataset), total_correct / len(\n",
        "      test_loader.dataset)\n",
        "\n",
        "def test_c(net, test_data, base_path):\n",
        "  \"\"\"Evaluate network on given corrupted dataset.\"\"\"\n",
        "  corruption_accs = []\n",
        "  for corruption in CORRUPTIONS:\n",
        "    # Reference to original data is mutated\n",
        "    test_data.data = np.load(base_path + corruption + '.npy')\n",
        "    test_data.targets = torch.LongTensor(np.load(base_path + 'labels.npy'))\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        batch_size=args.eval_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers,\n",
        "        pin_memory=True)\n",
        "\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "    corruption_accs.append(test_acc)\n",
        "    print('{}\\n\\tTest Loss {:.3f} | Test Error {:.3f}'.format(\n",
        "        corruption, test_loss, 100 - 100. * test_acc))\n",
        "\n",
        "  return np.mean(corruption_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZyJ5kICtRTF"
      },
      "source": [
        "# Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jARbLlUvtRTF"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  \"\"\"Basic ResNet block.\"\"\"\n",
        "\n",
        "  def __init__(self, in_planes, out_planes, stride, drop_rate=0.0):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "    self.relu1 = nn.ReLU(inplace=True)\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=1,\n",
        "        bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "    self.relu2 = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.drop_rate = drop_rate\n",
        "    self.is_in_equal_out = (in_planes == out_planes)\n",
        "    self.conv_shortcut = (not self.is_in_equal_out) and nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=1,\n",
        "        stride=stride,\n",
        "        padding=0,\n",
        "        bias=False) or None\n",
        "\n",
        "  def forward(self, x):\n",
        "    if not self.is_in_equal_out:\n",
        "      x = self.relu1(self.bn1(x))\n",
        "    else:\n",
        "      out = self.relu1(self.bn1(x))\n",
        "    if self.is_in_equal_out:\n",
        "      out = self.relu2(self.bn2(self.conv1(out)))\n",
        "    else:\n",
        "      out = self.relu2(self.bn2(self.conv1(x)))\n",
        "    if self.drop_rate > 0:\n",
        "      out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
        "    out = self.conv2(out)\n",
        "    if not self.is_in_equal_out:\n",
        "      return torch.add(self.conv_shortcut(x), out)\n",
        "    else:\n",
        "      return torch.add(x, out)\n",
        "\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "  \"\"\"Layer container for blocks.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               nb_layers,\n",
        "               in_planes,\n",
        "               out_planes,\n",
        "               block,\n",
        "               stride,\n",
        "               drop_rate=0.0):\n",
        "    super(NetworkBlock, self).__init__()\n",
        "    self.layer = self._make_layer(block, in_planes, out_planes, nb_layers,\n",
        "                                  stride, drop_rate)\n",
        "\n",
        "  def _make_layer(self, block, in_planes, out_planes, nb_layers, stride,\n",
        "                  drop_rate):\n",
        "    layers = []\n",
        "    for i in range(nb_layers):\n",
        "      layers.append(\n",
        "          block(i == 0 and in_planes or out_planes, out_planes,\n",
        "                i == 0 and stride or 1, drop_rate))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "  \"\"\"WideResNet class.\"\"\"\n",
        "\n",
        "  def __init__(self, depth, num_classes, widen_factor=1, drop_rate=0.0):\n",
        "    super(WideResNet, self).__init__()\n",
        "    n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
        "    assert (depth - 4) % 6 == 0\n",
        "    n = (depth - 4) // 6\n",
        "    block = BasicBlock\n",
        "    # 1st conv before any network block\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    # 1st block\n",
        "    self.block1 = NetworkBlock(n, n_channels[0], n_channels[1], block, 1,\n",
        "                               drop_rate)\n",
        "    # 2nd block\n",
        "    self.block2 = NetworkBlock(n, n_channels[1], n_channels[2], block, 2,\n",
        "                               drop_rate)\n",
        "    # 3rd block\n",
        "    self.block3 = NetworkBlock(n, n_channels[2], n_channels[3], block, 2,\n",
        "                               drop_rate)\n",
        "    # global average pooling and classifier\n",
        "    self.bn1 = nn.BatchNorm2d(n_channels[3])\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.fc = nn.Linear(n_channels[3], num_classes)\n",
        "    self.n_channels = n_channels[3]\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.block1(out)\n",
        "    out = self.block2(out)\n",
        "    out = self.block3(out)\n",
        "    out = self.relu(self.bn1(out))\n",
        "    out = F.avg_pool2d(out, 8)\n",
        "    out = out.view(-1, self.n_channels)\n",
        "    return self.fc(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aP722ptRTF"
      },
      "source": [
        "# Model settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3izC1C9ItRTF"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    dataset = 'cifar10'  # or 'cifar100'\n",
        "    model = 'wrn'  # 'densenet', 'wrn', 'allconv', 'resnext'\n",
        "    batch_size = 128\n",
        "    eval_batch_size = 1000\n",
        "    num_workers = 0\n",
        "    no_jsd = True\n",
        "    layers = 40\n",
        "    widen_factor = 2\n",
        "    droprate = 0.0\n",
        "    learning_rate = 0.1\n",
        "    momentum = 0.9\n",
        "    decay = 0.0005\n",
        "    epochs = 50\n",
        "    print_freq = 100\n",
        "    resume = None  # path to checkpoint\n",
        "    evaluate = True\n",
        "    save = './checkpoints'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    # GPU operations have a separate seed we also want to set\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed = 42\n",
        "setup_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pnYhjVuPtRTF"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4)\n",
        "])\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "test_transform = preprocess\n",
        "\n",
        "if args.dataset == 'cifar10':\n",
        "    train_data = datasets.CIFAR10('./data/cifar', train=True, transform=train_transform, download=True)\n",
        "    test_data = datasets.CIFAR10('./data/cifar', train=False, transform=test_transform, download=True)\n",
        "    base_c_path = './CIFAR-10-C/'\n",
        "    num_classes = 10\n",
        "else:\n",
        "    train_data = datasets.CIFAR100('./data/cifar', train=True, transform=train_transform, download=True)\n",
        "    test_data = datasets.CIFAR100('./data/cifar', train=False, transform=test_transform, download=True)\n",
        "    base_c_path = './CIFAR-100-C/'\n",
        "    num_classes = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gbDYs4V0tRTF"
      },
      "outputs": [],
      "source": [
        "train_data = AugMixDataset(train_data, preprocess, args.no_jsd)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "      train_data,\n",
        "      batch_size=args.batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=args.num_workers,\n",
        "      pin_memory=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "      test_data,\n",
        "      batch_size=args.eval_batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=args.num_workers,\n",
        "      pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UUCMkWSTtRTF"
      },
      "outputs": [],
      "source": [
        "CORRUPTIONS = [\n",
        "    'gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur',\n",
        "    'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog',\n",
        "    'brightness', 'contrast', 'elastic_transform', 'pixelate',\n",
        "    'jpeg_compression'\n",
        "]\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "  \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "  return lr_min + (lr_max - lr_min) * 0.5 * (1 +\n",
        "                                             np.cos(step / total_steps * np.pi))\n",
        "net = WideResNet(args.layers, num_classes, args.widen_factor, args.droprate)\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "      net.parameters(),\n",
        "      args.learning_rate,\n",
        "      momentum=args.momentum,\n",
        "      weight_decay=args.decay,\n",
        "      nesterov=True)\n",
        "\n",
        "net = torch.nn.DataParallel(net).cuda()\n",
        "cudnn.benchmark = True\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "      optimizer,\n",
        "      lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
        "          step,\n",
        "          args.epochs * len(train_loader),\n",
        "          1,  # lr_lambda computes multiplicative factor\n",
        "          1e-6 / args.learning_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-Iq9_l1-tRTF"
      },
      "outputs": [],
      "source": [
        "start_epoch = 0\n",
        "best_acc = 0\n",
        "if args.resume and os.path.isfile(args.resume):\n",
        "    checkpoint = torch.load(args.resume)\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    best_acc = checkpoint['best_acc']\n",
        "    net.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(f'Model restored from epoch {start_epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4or4ldc7tRTG",
        "outputId": "8689098b-9855-4a10-96ef-b6ea2c381a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from epoch 1\n",
            "Train Loss 0.236\n",
            "Train Loss 1.736\n",
            "Train Loss 1.549\n",
            "Train Loss 1.362\n",
            "Epoch   1 | Time   266s | Train Loss 1.2203 | Test Loss 0.001 | Test Error 44.08%\n",
            "Train Loss 0.124\n",
            "Train Loss 1.128\n",
            "Train Loss 0.993\n",
            "Train Loss 0.976\n",
            "Epoch   2 | Time   258s | Train Loss 0.9342 | Test Loss 0.001 | Test Error 35.47%\n",
            "Train Loss 0.100\n",
            "Train Loss 0.874\n",
            "Train Loss 0.847\n",
            "Train Loss 0.798\n",
            "Epoch   3 | Time   260s | Train Loss 0.8039 | Test Loss 0.001 | Test Error 27.28%\n",
            "Train Loss 0.087\n",
            "Train Loss 0.792\n",
            "Train Loss 0.768\n",
            "Train Loss 0.762\n",
            "Epoch   4 | Time   260s | Train Loss 0.7289 | Test Loss 0.001 | Test Error 30.90%\n",
            "Train Loss 0.055\n",
            "Train Loss 0.690\n",
            "Train Loss 0.685\n",
            "Train Loss 0.710\n",
            "Epoch   5 | Time   256s | Train Loss 0.6966 | Test Loss 0.001 | Test Error 27.25%\n",
            "Train Loss 0.076\n",
            "Train Loss 0.637\n",
            "Train Loss 0.633\n",
            "Train Loss 0.658\n",
            "Epoch   6 | Time   253s | Train Loss 0.6442 | Test Loss 0.001 | Test Error 23.54%\n",
            "Train Loss 0.073\n",
            "Train Loss 0.674\n",
            "Train Loss 0.624\n",
            "Train Loss 0.668\n",
            "Epoch   7 | Time   256s | Train Loss 0.6042 | Test Loss 0.001 | Test Error 21.34%\n",
            "Train Loss 0.060\n",
            "Train Loss 0.574\n",
            "Train Loss 0.626\n",
            "Train Loss 0.562\n",
            "Epoch   8 | Time   257s | Train Loss 0.6067 | Test Loss 0.001 | Test Error 22.21%\n",
            "Train Loss 0.063\n",
            "Train Loss 0.585\n",
            "Train Loss 0.561\n",
            "Train Loss 0.587\n",
            "Epoch   9 | Time   254s | Train Loss 0.6026 | Test Loss 0.001 | Test Error 23.65%\n",
            "Train Loss 0.058\n",
            "Train Loss 0.557\n",
            "Train Loss 0.561\n",
            "Train Loss 0.547\n",
            "Epoch  10 | Time   252s | Train Loss 0.5620 | Test Loss 0.001 | Test Error 18.68%\n",
            "Train Loss 0.065\n",
            "Train Loss 0.583\n",
            "Train Loss 0.525\n",
            "Train Loss 0.537\n",
            "Epoch  11 | Time   250s | Train Loss 0.5326 | Test Loss 0.001 | Test Error 19.22%\n",
            "Train Loss 0.050\n",
            "Train Loss 0.550\n",
            "Train Loss 0.564\n",
            "Train Loss 0.542\n",
            "Epoch  12 | Time   250s | Train Loss 0.5495 | Test Loss 0.001 | Test Error 20.65%\n",
            "Train Loss 0.056\n",
            "Train Loss 0.506\n",
            "Train Loss 0.504\n",
            "Train Loss 0.548\n",
            "Epoch  13 | Time   257s | Train Loss 0.5310 | Test Loss 0.001 | Test Error 19.80%\n",
            "Train Loss 0.045\n",
            "Train Loss 0.499\n",
            "Train Loss 0.493\n",
            "Train Loss 0.536\n",
            "Epoch  14 | Time   261s | Train Loss 0.5197 | Test Loss 0.001 | Test Error 21.36%\n",
            "Train Loss 0.046\n",
            "Train Loss 0.484\n",
            "Train Loss 0.505\n",
            "Train Loss 0.479\n",
            "Epoch  15 | Time   256s | Train Loss 0.4927 | Test Loss 0.001 | Test Error 21.05%\n",
            "Train Loss 0.044\n",
            "Train Loss 0.475\n",
            "Train Loss 0.480\n",
            "Train Loss 0.495\n",
            "Epoch  16 | Time   257s | Train Loss 0.5067 | Test Loss 0.001 | Test Error 19.05%\n",
            "Train Loss 0.047\n",
            "Train Loss 0.447\n",
            "Train Loss 0.485\n",
            "Train Loss 0.509\n",
            "Epoch  17 | Time   258s | Train Loss 0.4808 | Test Loss 0.001 | Test Error 18.78%\n",
            "Train Loss 0.048\n",
            "Train Loss 0.469\n",
            "Train Loss 0.462\n",
            "Train Loss 0.480\n",
            "Epoch  18 | Time   257s | Train Loss 0.4363 | Test Loss 0.001 | Test Error 17.99%\n",
            "Train Loss 0.044\n",
            "Train Loss 0.415\n",
            "Train Loss 0.441\n",
            "Train Loss 0.429\n",
            "Epoch  19 | Time   259s | Train Loss 0.4305 | Test Loss 0.001 | Test Error 17.85%\n",
            "Train Loss 0.046\n",
            "Train Loss 0.441\n",
            "Train Loss 0.410\n",
            "Train Loss 0.459\n",
            "Epoch  20 | Time   257s | Train Loss 0.4417 | Test Loss 0.000 | Test Error 14.04%\n",
            "Train Loss 0.045\n",
            "Train Loss 0.430\n",
            "Train Loss 0.409\n",
            "Train Loss 0.419\n",
            "Epoch  21 | Time   252s | Train Loss 0.4294 | Test Loss 0.000 | Test Error 16.03%\n",
            "Train Loss 0.045\n",
            "Train Loss 0.423\n",
            "Train Loss 0.409\n",
            "Train Loss 0.451\n",
            "Epoch  22 | Time   257s | Train Loss 0.3934 | Test Loss 0.001 | Test Error 16.03%\n",
            "Train Loss 0.039\n",
            "Train Loss 0.410\n",
            "Train Loss 0.394\n",
            "Train Loss 0.403\n",
            "Epoch  23 | Time   253s | Train Loss 0.4066 | Test Loss 0.000 | Test Error 15.40%\n",
            "Train Loss 0.037\n",
            "Train Loss 0.392\n",
            "Train Loss 0.384\n",
            "Train Loss 0.384\n",
            "Epoch  24 | Time   251s | Train Loss 0.4374 | Test Loss 0.000 | Test Error 13.69%\n",
            "Train Loss 0.036\n",
            "Train Loss 0.378\n",
            "Train Loss 0.384\n",
            "Train Loss 0.369\n",
            "Epoch  25 | Time   250s | Train Loss 0.4003 | Test Loss 0.000 | Test Error 12.34%\n",
            "Train Loss 0.040\n",
            "Train Loss 0.376\n",
            "Train Loss 0.359\n",
            "Train Loss 0.390\n",
            "Epoch  26 | Time   253s | Train Loss 0.3828 | Test Loss 0.000 | Test Error 12.94%\n",
            "Train Loss 0.030\n",
            "Train Loss 0.389\n",
            "Train Loss 0.377\n",
            "Train Loss 0.324\n",
            "Epoch  27 | Time   250s | Train Loss 0.3703 | Test Loss 0.000 | Test Error 12.13%\n",
            "Train Loss 0.029\n",
            "Train Loss 0.353\n",
            "Train Loss 0.356\n",
            "Train Loss 0.349\n",
            "Epoch  28 | Time   248s | Train Loss 0.3306 | Test Loss 0.000 | Test Error 12.41%\n",
            "Train Loss 0.039\n",
            "Train Loss 0.328\n",
            "Train Loss 0.359\n",
            "Train Loss 0.323\n",
            "Epoch  29 | Time   249s | Train Loss 0.3411 | Test Loss 0.000 | Test Error 11.49%\n",
            "Train Loss 0.029\n",
            "Train Loss 0.318\n",
            "Train Loss 0.329\n",
            "Train Loss 0.339\n",
            "Epoch  30 | Time   255s | Train Loss 0.3365 | Test Loss 0.000 | Test Error 11.45%\n",
            "Train Loss 0.036\n",
            "Train Loss 0.329\n",
            "Train Loss 0.329\n",
            "Train Loss 0.324\n",
            "Epoch  31 | Time   251s | Train Loss 0.2922 | Test Loss 0.000 | Test Error 11.25%\n",
            "Train Loss 0.021\n",
            "Train Loss 0.257\n",
            "Train Loss 0.287\n",
            "Train Loss 0.312\n",
            "Epoch  32 | Time   253s | Train Loss 0.2629 | Test Loss 0.000 | Test Error 9.35%\n",
            "Train Loss 0.032\n",
            "Train Loss 0.264\n",
            "Train Loss 0.299\n",
            "Train Loss 0.291\n",
            "Epoch  33 | Time   252s | Train Loss 0.2792 | Test Loss 0.000 | Test Error 9.87%\n",
            "Train Loss 0.024\n",
            "Train Loss 0.283\n",
            "Train Loss 0.258\n",
            "Train Loss 0.249\n",
            "Epoch  34 | Time   254s | Train Loss 0.2714 | Test Loss 0.000 | Test Error 9.35%\n",
            "Train Loss 0.019\n",
            "Train Loss 0.251\n",
            "Train Loss 0.260\n",
            "Train Loss 0.278\n",
            "Epoch  35 | Time   253s | Train Loss 0.2845 | Test Loss 0.000 | Test Error 9.40%\n",
            "Train Loss 0.026\n",
            "Train Loss 0.222\n",
            "Train Loss 0.245\n",
            "Train Loss 0.223\n",
            "Epoch  36 | Time   252s | Train Loss 0.2361 | Test Loss 0.000 | Test Error 9.72%\n",
            "Train Loss 0.024\n",
            "Train Loss 0.244\n",
            "Train Loss 0.223\n",
            "Train Loss 0.218\n",
            "Epoch  37 | Time   259s | Train Loss 0.2059 | Test Loss 0.000 | Test Error 8.10%\n",
            "Train Loss 0.022\n",
            "Train Loss 0.203\n",
            "Train Loss 0.212\n",
            "Train Loss 0.206\n",
            "Epoch  38 | Time   253s | Train Loss 0.1898 | Test Loss 0.000 | Test Error 7.99%\n",
            "Train Loss 0.021\n",
            "Train Loss 0.190\n",
            "Train Loss 0.190\n",
            "Train Loss 0.187\n",
            "Epoch  39 | Time   251s | Train Loss 0.1911 | Test Loss 0.000 | Test Error 7.45%\n",
            "Train Loss 0.010\n",
            "Train Loss 0.174\n",
            "Train Loss 0.153\n",
            "Train Loss 0.172\n",
            "Epoch  40 | Time   252s | Train Loss 0.1704 | Test Loss 0.000 | Test Error 7.05%\n",
            "Train Loss 0.015\n",
            "Train Loss 0.160\n",
            "Train Loss 0.149\n",
            "Train Loss 0.147\n",
            "Epoch  41 | Time   253s | Train Loss 0.1568 | Test Loss 0.000 | Test Error 7.26%\n",
            "Train Loss 0.018\n",
            "Train Loss 0.133\n",
            "Train Loss 0.142\n",
            "Train Loss 0.142\n",
            "Epoch  42 | Time   251s | Train Loss 0.1410 | Test Loss 0.000 | Test Error 6.75%\n",
            "Train Loss 0.012\n",
            "Train Loss 0.125\n",
            "Train Loss 0.134\n",
            "Train Loss 0.138\n",
            "Epoch  43 | Time   252s | Train Loss 0.1287 | Test Loss 0.000 | Test Error 6.25%\n",
            "Train Loss 0.011\n",
            "Train Loss 0.125\n",
            "Train Loss 0.136\n",
            "Train Loss 0.107\n",
            "Epoch  44 | Time   250s | Train Loss 0.1198 | Test Loss 0.000 | Test Error 6.49%\n",
            "Train Loss 0.011\n",
            "Train Loss 0.110\n",
            "Train Loss 0.116\n",
            "Train Loss 0.100\n",
            "Epoch  45 | Time   251s | Train Loss 0.1026 | Test Loss 0.000 | Test Error 6.02%\n",
            "Train Loss 0.013\n",
            "Train Loss 0.103\n",
            "Train Loss 0.107\n",
            "Train Loss 0.116\n",
            "Epoch  46 | Time   251s | Train Loss 0.0901 | Test Loss 0.000 | Test Error 5.95%\n",
            "Train Loss 0.013\n",
            "Train Loss 0.095\n",
            "Train Loss 0.095\n",
            "Train Loss 0.084\n",
            "Epoch  47 | Time   254s | Train Loss 0.0985 | Test Loss 0.000 | Test Error 5.77%\n",
            "Train Loss 0.007\n",
            "Train Loss 0.091\n",
            "Train Loss 0.085\n",
            "Train Loss 0.089\n",
            "Epoch  48 | Time   255s | Train Loss 0.0935 | Test Loss 0.000 | Test Error 5.87%\n",
            "Train Loss 0.010\n",
            "Train Loss 0.098\n",
            "Train Loss 0.090\n",
            "Train Loss 0.092\n",
            "Epoch  49 | Time   252s | Train Loss 0.0919 | Test Loss 0.000 | Test Error 5.79%\n",
            "Train Loss 0.008\n",
            "Train Loss 0.092\n",
            "Train Loss 0.089\n",
            "Train Loss 0.077\n",
            "Epoch  50 | Time   255s | Train Loss 0.0906 | Test Loss 0.000 | Test Error 5.82%\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(args.save):\n",
        "    os.makedirs(args.save)\n",
        "\n",
        "log_path = os.path.join(args.save, f'{args.dataset}_{args.model}_training_log.csv')\n",
        "with open(log_path, 'w') as f:\n",
        "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
        "\n",
        "print(f'Starting training from epoch {start_epoch + 1}')\n",
        "for epoch in range(start_epoch, args.epochs):\n",
        "    begin_time = time.time()\n",
        "\n",
        "    train_loss_ema = train(net, train_loader, optimizer, scheduler)\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "\n",
        "    is_best = test_acc > best_acc\n",
        "    best_acc = max(test_acc, best_acc)\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'dataset': args.dataset,\n",
        "        'model': args.model,\n",
        "        'state_dict': net.state_dict(),\n",
        "        'best_acc': best_acc,\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "    save_path = os.path.join(args.save, 'checkpoint.pth.tar')\n",
        "    torch.save(checkpoint, save_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(save_path, os.path.join(args.save, 'model_best.pth.tar'))\n",
        "\n",
        "    with open(log_path, 'a') as f:\n",
        "        f.write(f'{epoch+1:03d},{int(time.time() - begin_time):05d},{train_loss_ema:.6f},{test_loss:.5f},{100 - 100. * test_acc:.2f}\\n')\n",
        "\n",
        "    print(f'Epoch {epoch+1:3d} | Time {int(time.time() - begin_time):5d}s | '\n",
        "          f'Train Loss {train_loss_ema:.4f} | Test Loss {test_loss:.3f} | '\n",
        "          f'Test Error {100 - 100. * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4hUSSW3UnIU",
        "outputId": "2563562a-2a7c-470c-c041-add88ce4d989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean\n",
            "\tTest Loss 0.000 | Test Accuracy 94.18%\n"
          ]
        }
      ],
      "source": [
        "if args.evaluate:\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "    print(f'Clean\\n\\tTest Loss {test_loss:.3f} | Test Accuracy {test_acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4ZAmlrrStRTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ba1bcf-9f8c-46ba-bcd7-e77b88beff92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gaussian_noise\n",
            "\tTest Loss 0.001 | Test Error 18.978\n",
            "shot_noise\n",
            "\tTest Loss 0.000 | Test Error 14.556\n",
            "impulse_noise\n",
            "\tTest Loss 0.001 | Test Error 17.316\n",
            "defocus_blur\n",
            "\tTest Loss 0.000 | Test Error 8.030\n",
            "glass_blur\n",
            "\tTest Loss 0.001 | Test Error 28.374\n",
            "motion_blur\n",
            "\tTest Loss 0.000 | Test Error 10.970\n",
            "zoom_blur\n",
            "\tTest Loss 0.000 | Test Error 9.882\n",
            "snow\n",
            "\tTest Loss 0.000 | Test Error 13.202\n",
            "frost\n",
            "\tTest Loss 0.000 | Test Error 12.422\n",
            "fog\n",
            "\tTest Loss 0.000 | Test Error 9.538\n",
            "brightness\n",
            "\tTest Loss 0.000 | Test Error 6.694\n",
            "contrast\n",
            "\tTest Loss 0.000 | Test Error 13.448\n",
            "elastic_transform\n",
            "\tTest Loss 0.000 | Test Error 12.934\n",
            "pixelate\n",
            "\tTest Loss 0.001 | Test Error 14.552\n",
            "jpeg_compression\n",
            "\tTest Loss 0.001 | Test Error 15.598\n",
            "Mean Corruption Error: 13.77%\n"
          ]
        }
      ],
      "source": [
        "test_c_acc = test_c(net, test_data, base_c_path)\n",
        "print(f'Mean Corruption Error: {100 - 100. * test_c_acc:.2f}%')\n",
        "\n",
        "with open(log_path, 'a') as f:\n",
        "    f.write(f'{args.epochs + 1:03d},00000,0.000000,0.00000,{100 - 100 * test_c_acc:.2f}\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}