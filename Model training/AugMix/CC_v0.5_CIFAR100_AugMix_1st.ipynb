{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o8vuKPT6tRTD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from random import random\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P4PAT1gtRTD"
      },
      "source": [
        "# Augmentation operations and list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ACY6bkltRTE"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 32\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  return float(level) * maxval / 10.\n",
        "\n",
        "def sample_level(n):\n",
        "  return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "def vipaug_g_prep(img, _):\n",
        "        kernel = 2 #cifar is 2, imagenet is dunno\n",
        "        vital = 0.005 #cifar10: 0.001, cifar100: 0.005, imagenet:  0.001\n",
        "        nonvital = 0.012 #cifar10: 0.014, cifar100: 0.012, imagenet:  0.005\n",
        "        fft = np.fft.fftn(img)\n",
        "        absolute = np.abs(fft)\n",
        "        noise_phase = np.zeros((np.shape(img)[0],np.shape(img)[1],np.shape(img)[2]))\n",
        "        # kernel filter\n",
        "        for p in range(3):\n",
        "            index_list = []\n",
        "            for i in range(len(absolute[:,:,p])//kernel):\n",
        "                for j in range(len(absolute[:,:,p])//kernel):\n",
        "                    number_list = []\n",
        "\n",
        "                    for k2 in range(kernel):\n",
        "                        for k1 in range(kernel):\n",
        "                            number_list.append(absolute[:,:,p][kernel*i + k2, kernel*j + k1])\n",
        "\n",
        "                    index = number_list.index(max(number_list))\n",
        "                    k3 = index // kernel\n",
        "                    k4 = index % kernel\n",
        "\n",
        "                    #save index\n",
        "                    index_x = kernel*i + k3\n",
        "                    index_y = kernel*j + k4\n",
        "                    index_list.append(np.array([index_x,index_y]))\n",
        "\n",
        "            #make ones matrix\n",
        "            mask = np.ones((np.shape(img)[0],np.shape(img)[1]))\n",
        "            #make masked matrix\n",
        "            for i1 in range(len(index_list)):\n",
        "                mask[index_list[i1][0],index_list[i1][1]] = 0\n",
        "\n",
        "            #add gaussian noise at phase\n",
        "            mask_vital = mask - np.ones((np.shape(img)[0],np.shape(img)[1]))\n",
        "            mask_vital = mask_vital * (-1)\n",
        "\n",
        "            gaussian_noise_vital = np.random.normal(0,vital**0.5,(np.shape(img)[0],np.shape(img)[1]))\n",
        "            gaussian_noise = np.random.normal(0,nonvital**0.5,(np.shape(img)[0],np.shape(img)[1]))\n",
        "            masked_gaussian_noise = mask * gaussian_noise\n",
        "\n",
        "            masked_gaussian_noise_vital = mask_vital * gaussian_noise_vital\n",
        "            noise_phase[:,:,p] = np.angle(fft[:,:,p]) + masked_gaussian_noise + masked_gaussian_noise_vital\n",
        "\n",
        "        return noise_phase\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "  return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "  return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 4)\n",
        "  return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "  degrees = int_parameter(sample_level(level), 30)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    degrees = -degrees\n",
        "  return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 256)\n",
        "  return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def color(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def contrast(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def brightness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def sharpness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "def nothing(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return pil_img\n",
        "\n",
        "def vipaug_g(x, _):\n",
        "        op = np.random.choice(augmentations_vipaug_list)\n",
        "        # print(\"first:\", op)\n",
        "        fft_before = np.fft.fftn(x)\n",
        "        x = op(x, 3)\n",
        "\n",
        "        x_aug = x.copy()\n",
        "        op = np.random.choice(augmentations_vipaug_list)\n",
        "        # print(\"second:\",op)\n",
        "        x_aug = op(x_aug, 3)\n",
        "\n",
        "        x = np.array(x).astype(np.uint8)\n",
        "        x_aug = np.array(x_aug).astype(np.uint8)\n",
        "\n",
        "        fft_1 = np.fft.fftn(x)\n",
        "\n",
        "        fft_2 = np.fft.fftn(x_aug)\n",
        "        # print(\"Difference between fft_1 and fft_2 (after phase swap):\", np.abs(fft_1 - fft_2).mean())\n",
        "\n",
        "        p = random.uniform(0, 1)\n",
        "        if p > 0.5: #VIPAug-G probability\n",
        "            # print(\"first pass!\", p)\n",
        "            abs_1, angle_1 = np.abs(fft_1), np.angle(fft_1)\n",
        "            abs_2, angle_2 = np.abs(fft_2), np.angle(fft_2)\n",
        "\n",
        "            fft_1 = abs_1*np.exp((1j) * angle_2)\n",
        "            fft_2 = abs_2*np.exp((1j) * angle_1)\n",
        "            # print(\"First pass fft_1 and fft_2:\", np.abs(fft_1 - fft_2).mean())\n",
        "\n",
        "            p = random.uniform(0, 1)\n",
        "            # print(\"in first pass\", p)\n",
        "\n",
        "            if p > 0.5:\n",
        "                x = np.fft.ifftn(fft_1)\n",
        "            else:\n",
        "                x = np.fft.ifftn(fft_2)\n",
        "\n",
        "        else:\n",
        "            p = random.uniform(0, 1)\n",
        "            # print(\"second pass!\", p)\n",
        "            if p > 0.5:\n",
        "                # print(\"third pass!\", p)\n",
        "                angle_2 = vipaug_g_prep(x_aug, _)\n",
        "                fft_1 = np.abs(fft_1)*np.exp((1j) * angle_2)\n",
        "                x = np.fft.ifftn(fft_1)\n",
        "            else:\n",
        "                # print(\"fourth pass!\", p)\n",
        "                angle_1 = vipaug_g_prep(x, _)\n",
        "                fft_2 = np.abs(fft_2)*np.exp((1j) * angle_1)\n",
        "                x = np.fft.ifftn(fft_2)\n",
        "\n",
        "        x = np.real(x)\n",
        "        x = np.clip(x, 0, 255).astype(np.uint8)\n",
        "        x = Image.fromarray(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "augmentations_vipaug_list = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y]\n",
        "\n",
        "augmentations = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y]\n",
        "\n",
        "augmentations_all = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, vipaug_g, color, contrast, brightness, sharpness]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGmqyTn6mayi"
      },
      "outputs": [],
      "source": [
        "image, label = train_data[11]\n",
        "augie_mage = aug(image, preprocess)\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-1.0, -1.0, -1.0],\n",
        "    std=[2.0, 2.0, 2.0]\n",
        ")\n",
        "augie_mage = inv_normalize(augie_mage).clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy()\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "ax1.imshow(image)\n",
        "ax1.set_title(\"Original\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(augie_mage)\n",
        "ax2.set_title(\"VipAug\")\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYm0Jy-vtRTE",
        "outputId": "47e4c94b-a3c9-445a-8704-e172325a34be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image, label = train_data[10]\n",
        "aug_image = aug(image, preprocess)\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-1.0, -1.0, -1.0],\n",
        "    std=[2.0, 2.0, 2.0]\n",
        ")\n",
        "\n",
        "# Undo normalization and convert to numpy\n",
        "aug_image = inv_normalize(aug_image).clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
        "\n",
        "ax1.imshow(image)\n",
        "ax1.set_title(\"Original\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(aug_image)\n",
        "ax2.set_title(\"Autocontrast\")\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2yA1XZmtRTE"
      },
      "source": [
        "# Mix augmentations final image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L6nmQPgKtRTE"
      },
      "outputs": [],
      "source": [
        "def aug(image, preprocess):\n",
        "  \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "\n",
        "  Args:\n",
        "    image: PIL.Image input image\n",
        "    preprocess: Preprocessing function which should return a torch tensor.\n",
        "\n",
        "  Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "  \"\"\"\n",
        "  aug_list = augmentations\n",
        "\n",
        "  ws = np.float32(np.random.dirichlet([1] * 3))\n",
        "  m = np.float32(np.random.beta(1, 1))\n",
        "\n",
        "  mix = torch.zeros_like(preprocess(image))\n",
        "  for i in range(3):\n",
        "    image_aug = image.copy()\n",
        "    depth = -1 if -1 > 0 else np.random.randint(\n",
        "        1, 4)\n",
        "    # print(\"depth:\", depth)\n",
        "    for _ in range(depth):\n",
        "      op = np.random.choice(aug_list)\n",
        "      # print(\"aug combinations:\", op)\n",
        "      image_aug = op(image_aug, 3)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * preprocess(image_aug)\n",
        "\n",
        "  mixed = (1 - m) * preprocess(image) + m * mix\n",
        "  return mixed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdpEmxdbtRTF"
      },
      "source": [
        "# Make Dataset out of augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7wU4USustRTF"
      },
      "outputs": [],
      "source": [
        "class AugMixDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"Dataset wrapper to perform AugMix augmentation.\"\"\"\n",
        "\n",
        "  def __init__(self, dataset, preprocess, no_jsd=True):\n",
        "    self.dataset = dataset\n",
        "    self.preprocess = preprocess\n",
        "    self.no_jsd = no_jsd\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.dataset[i]\n",
        "    if self.no_jsd:\n",
        "      return aug(x, self.preprocess), y\n",
        "    else:\n",
        "      im_tuple = (self.preprocess(x), aug(x, self.preprocess),\n",
        "                  aug(x, self.preprocess))\n",
        "      return im_tuple, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv3GkpoItRTF"
      },
      "source": [
        "# Training and Test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XBrq7-NstRTF"
      },
      "outputs": [],
      "source": [
        "def train(net, train_loader, optimizer, scheduler, no_jsd=True, print_freq=100):\n",
        "  \"\"\"Train for one epoch.\"\"\"\n",
        "  net.train()\n",
        "  loss_ema = 0.\n",
        "  for i, (images, targets) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if no_jsd:\n",
        "      images = images.cuda()\n",
        "      targets = targets.cuda()\n",
        "      logits = net(images)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    else:\n",
        "      images_all = torch.cat(images, 0).cuda()\n",
        "      targets = targets.cuda()\n",
        "      logits_all = net(images_all)\n",
        "      logits_clean, logits_aug1, logits_aug2 = torch.split(\n",
        "          logits_all, images[0].size(0))\n",
        "\n",
        "      # Cross-entropy is only computed on clean images\n",
        "      loss = F.cross_entropy(logits_clean, targets)\n",
        "\n",
        "      p_clean, p_aug1, p_aug2 = F.softmax(\n",
        "          logits_clean, dim=1), F.softmax(\n",
        "              logits_aug1, dim=1), F.softmax(\n",
        "                  logits_aug2, dim=1)\n",
        "\n",
        "      # Clamp mixture distribution to avoid exploding KL divergence\n",
        "      p_mixture = torch.clamp((p_clean + p_aug1 + p_aug2) / 3., 1e-7, 1).log()\n",
        "      loss += 12 * (F.kl_div(p_mixture, p_clean, reduction='batchmean') +\n",
        "                    F.kl_div(p_mixture, p_aug1, reduction='batchmean') +\n",
        "                    F.kl_div(p_mixture, p_aug2, reduction='batchmean')) / 3.\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    loss_ema = loss_ema * 0.9 + float(loss) * 0.1\n",
        "    if i % args.print_freq == 0:\n",
        "      print('Train Loss {:.3f}'.format(loss_ema))\n",
        "\n",
        "  return loss_ema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EBsCYDIMtRTF"
      },
      "outputs": [],
      "source": [
        "def test(net, test_loader):\n",
        "  \"\"\"Evaluate network on given dataset.\"\"\"\n",
        "  net.eval()\n",
        "  total_loss = 0.\n",
        "  total_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for images, targets in test_loader:\n",
        "      images, targets = images.cuda(), targets.cuda()\n",
        "      logits = net(images)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "      pred = logits.data.max(1)[1]\n",
        "      total_loss += float(loss.data)\n",
        "      total_correct += pred.eq(targets.data).sum().item()\n",
        "\n",
        "  return total_loss / len(test_loader.dataset), total_correct / len(\n",
        "      test_loader.dataset)\n",
        "\n",
        "def test_c(net, test_data, base_path):\n",
        "  \"\"\"Evaluate network on given corrupted dataset.\"\"\"\n",
        "  corruption_accs = []\n",
        "  for corruption in CORRUPTIONS:\n",
        "    # Reference to original data is mutated\n",
        "    test_data.data = np.load(base_path + corruption + '.npy')\n",
        "    test_data.targets = torch.LongTensor(np.load(base_path + 'labels.npy'))\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        batch_size=args.eval_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers,\n",
        "        pin_memory=True)\n",
        "\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "    corruption_accs.append(test_acc)\n",
        "    print('{}\\n\\tTest Loss {:.3f} | Test Error {:.3f}'.format(\n",
        "        corruption, test_loss, 100 - 100. * test_acc))\n",
        "\n",
        "  return np.mean(corruption_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZyJ5kICtRTF"
      },
      "source": [
        "# Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jARbLlUvtRTF"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  \"\"\"Basic ResNet block.\"\"\"\n",
        "\n",
        "  def __init__(self, in_planes, out_planes, stride, drop_rate=0.0):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "    self.relu1 = nn.ReLU(inplace=True)\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=1,\n",
        "        bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "    self.relu2 = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.drop_rate = drop_rate\n",
        "    self.is_in_equal_out = (in_planes == out_planes)\n",
        "    self.conv_shortcut = (not self.is_in_equal_out) and nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=1,\n",
        "        stride=stride,\n",
        "        padding=0,\n",
        "        bias=False) or None\n",
        "\n",
        "  def forward(self, x):\n",
        "    if not self.is_in_equal_out:\n",
        "      x = self.relu1(self.bn1(x))\n",
        "    else:\n",
        "      out = self.relu1(self.bn1(x))\n",
        "    if self.is_in_equal_out:\n",
        "      out = self.relu2(self.bn2(self.conv1(out)))\n",
        "    else:\n",
        "      out = self.relu2(self.bn2(self.conv1(x)))\n",
        "    if self.drop_rate > 0:\n",
        "      out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
        "    out = self.conv2(out)\n",
        "    if not self.is_in_equal_out:\n",
        "      return torch.add(self.conv_shortcut(x), out)\n",
        "    else:\n",
        "      return torch.add(x, out)\n",
        "\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "  \"\"\"Layer container for blocks.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               nb_layers,\n",
        "               in_planes,\n",
        "               out_planes,\n",
        "               block,\n",
        "               stride,\n",
        "               drop_rate=0.0):\n",
        "    super(NetworkBlock, self).__init__()\n",
        "    self.layer = self._make_layer(block, in_planes, out_planes, nb_layers,\n",
        "                                  stride, drop_rate)\n",
        "\n",
        "  def _make_layer(self, block, in_planes, out_planes, nb_layers, stride,\n",
        "                  drop_rate):\n",
        "    layers = []\n",
        "    for i in range(nb_layers):\n",
        "      layers.append(\n",
        "          block(i == 0 and in_planes or out_planes, out_planes,\n",
        "                i == 0 and stride or 1, drop_rate))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "  \"\"\"WideResNet class.\"\"\"\n",
        "\n",
        "  def __init__(self, depth, num_classes, widen_factor=1, drop_rate=0.0):\n",
        "    super(WideResNet, self).__init__()\n",
        "    n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
        "    assert (depth - 4) % 6 == 0\n",
        "    n = (depth - 4) // 6\n",
        "    block = BasicBlock\n",
        "    # 1st conv before any network block\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    # 1st block\n",
        "    self.block1 = NetworkBlock(n, n_channels[0], n_channels[1], block, 1,\n",
        "                               drop_rate)\n",
        "    # 2nd block\n",
        "    self.block2 = NetworkBlock(n, n_channels[1], n_channels[2], block, 2,\n",
        "                               drop_rate)\n",
        "    # 3rd block\n",
        "    self.block3 = NetworkBlock(n, n_channels[2], n_channels[3], block, 2,\n",
        "                               drop_rate)\n",
        "    # global average pooling and classifier\n",
        "    self.bn1 = nn.BatchNorm2d(n_channels[3])\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.fc = nn.Linear(n_channels[3], num_classes)\n",
        "    self.n_channels = n_channels[3]\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.block1(out)\n",
        "    out = self.block2(out)\n",
        "    out = self.block3(out)\n",
        "    out = self.relu(self.bn1(out))\n",
        "    out = F.avg_pool2d(out, 8)\n",
        "    out = out.view(-1, self.n_channels)\n",
        "    return self.fc(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aP722ptRTF"
      },
      "source": [
        "# Model settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3izC1C9ItRTF"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    dataset = 'cifar100'  # or 'cifar100'\n",
        "    model = 'wrn'  # 'densenet', 'wrn', 'allconv', 'resnext'\n",
        "    batch_size = 128\n",
        "    eval_batch_size = 1000\n",
        "    num_workers = 0\n",
        "    no_jsd = True\n",
        "    layers = 40\n",
        "    widen_factor = 2\n",
        "    droprate = 0.0\n",
        "    learning_rate = 0.1\n",
        "    momentum = 0.9\n",
        "    decay = 0.0005\n",
        "    epochs = 50\n",
        "    print_freq = 100\n",
        "    resume = None  # path to checkpoint\n",
        "    evaluate = True\n",
        "    save = './checkpoints'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    # GPU operations have a separate seed we also want to set\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed = 42\n",
        "setup_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pnYhjVuPtRTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f5a9a9-84f8-4415-fe2f-2c477b5e3a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:18<00:00, 9.18MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4)\n",
        "])\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "test_transform = preprocess\n",
        "\n",
        "if args.dataset == 'cifar10':\n",
        "    train_data = datasets.CIFAR10('./data/cifar', train=True, transform=train_transform, download=True)\n",
        "    test_data = datasets.CIFAR10('./data/cifar', train=False, transform=test_transform, download=True)\n",
        "    base_c_path = './CIFAR-10-C/'\n",
        "    num_classes = 10\n",
        "else:\n",
        "    train_data = datasets.CIFAR100('./data/cifar', train=True, transform=train_transform, download=True)\n",
        "    test_data = datasets.CIFAR100('./data/cifar', train=False, transform=test_transform, download=True)\n",
        "    base_c_path = './CIFAR-100-C/'\n",
        "    num_classes = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gbDYs4V0tRTF"
      },
      "outputs": [],
      "source": [
        "train_data = AugMixDataset(train_data, preprocess, args.no_jsd)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "      train_data,\n",
        "      batch_size=args.batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=args.num_workers,\n",
        "      pin_memory=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "      test_data,\n",
        "      batch_size=args.eval_batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=args.num_workers,\n",
        "      pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UUCMkWSTtRTF"
      },
      "outputs": [],
      "source": [
        "CORRUPTIONS = [\n",
        "    'gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur',\n",
        "    'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog',\n",
        "    'brightness', 'contrast', 'elastic_transform', 'pixelate',\n",
        "    'jpeg_compression'\n",
        "]\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "  \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "  return lr_min + (lr_max - lr_min) * 0.5 * (1 +\n",
        "                                             np.cos(step / total_steps * np.pi))\n",
        "net = WideResNet(args.layers, num_classes, args.widen_factor, args.droprate)\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "      net.parameters(),\n",
        "      args.learning_rate,\n",
        "      momentum=args.momentum,\n",
        "      weight_decay=args.decay,\n",
        "      nesterov=True)\n",
        "\n",
        "net = torch.nn.DataParallel(net).cuda()\n",
        "cudnn.benchmark = True\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "      optimizer,\n",
        "      lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
        "          step,\n",
        "          args.epochs * len(train_loader),\n",
        "          1,  # lr_lambda computes multiplicative factor\n",
        "          1e-6 / args.learning_rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-Iq9_l1-tRTF"
      },
      "outputs": [],
      "source": [
        "start_epoch = 0\n",
        "best_acc = 0\n",
        "if args.resume and os.path.isfile(args.resume):\n",
        "    checkpoint = torch.load(args.resume)\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    best_acc = checkpoint['best_acc']\n",
        "    net.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print(f'Model restored from epoch {start_epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4or4ldc7tRTG",
        "outputId": "9ed22c50-0527-41f5-b2ad-7e60cd2a3686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from epoch 1\n",
            "Train Loss 0.464\n",
            "Train Loss 4.178\n",
            "Train Loss 3.991\n",
            "Train Loss 3.826\n",
            "Epoch   1 | Time   168s | Train Loss 3.6505 | Test Loss 0.004 | Test Error 85.31%\n",
            "Train Loss 0.363\n",
            "Train Loss 3.515\n",
            "Train Loss 3.335\n",
            "Train Loss 3.260\n",
            "Epoch   2 | Time   161s | Train Loss 3.0789 | Test Loss 0.003 | Test Error 79.06%\n",
            "Train Loss 0.320\n",
            "Train Loss 2.984\n",
            "Train Loss 2.944\n",
            "Train Loss 2.783\n",
            "Epoch   3 | Time   160s | Train Loss 2.6586 | Test Loss 0.003 | Test Error 73.05%\n",
            "Train Loss 0.242\n",
            "Train Loss 2.578\n",
            "Train Loss 2.590\n",
            "Train Loss 2.450\n",
            "Epoch   4 | Time   157s | Train Loss 2.4483 | Test Loss 0.003 | Test Error 70.99%\n",
            "Train Loss 0.239\n",
            "Train Loss 2.348\n",
            "Train Loss 2.299\n",
            "Train Loss 2.341\n",
            "Epoch   5 | Time   157s | Train Loss 2.2125 | Test Loss 0.002 | Test Error 61.70%\n",
            "Train Loss 0.234\n",
            "Train Loss 2.135\n",
            "Train Loss 2.092\n",
            "Train Loss 2.086\n",
            "Epoch   6 | Time   155s | Train Loss 2.1316 | Test Loss 0.002 | Test Error 56.90%\n",
            "Train Loss 0.221\n",
            "Train Loss 2.026\n",
            "Train Loss 1.962\n",
            "Train Loss 2.018\n",
            "Epoch   7 | Time   153s | Train Loss 1.9815 | Test Loss 0.002 | Test Error 55.74%\n",
            "Train Loss 0.179\n",
            "Train Loss 1.905\n",
            "Train Loss 1.876\n",
            "Train Loss 1.909\n",
            "Epoch   8 | Time   157s | Train Loss 1.8779 | Test Loss 0.002 | Test Error 55.82%\n",
            "Train Loss 0.194\n",
            "Train Loss 1.884\n",
            "Train Loss 1.898\n",
            "Train Loss 1.804\n",
            "Epoch   9 | Time   155s | Train Loss 1.8258 | Test Loss 0.002 | Test Error 51.43%\n",
            "Train Loss 0.178\n",
            "Train Loss 1.776\n",
            "Train Loss 1.821\n",
            "Train Loss 1.794\n",
            "Epoch  10 | Time   156s | Train Loss 1.8169 | Test Loss 0.002 | Test Error 51.01%\n",
            "Train Loss 0.175\n",
            "Train Loss 1.763\n",
            "Train Loss 1.752\n",
            "Train Loss 1.718\n",
            "Epoch  11 | Time   156s | Train Loss 1.7885 | Test Loss 0.002 | Test Error 52.72%\n",
            "Train Loss 0.167\n",
            "Train Loss 1.669\n",
            "Train Loss 1.675\n",
            "Train Loss 1.724\n",
            "Epoch  12 | Time   156s | Train Loss 1.7695 | Test Loss 0.002 | Test Error 52.75%\n",
            "Train Loss 0.166\n",
            "Train Loss 1.640\n",
            "Train Loss 1.688\n",
            "Train Loss 1.647\n",
            "Epoch  13 | Time   156s | Train Loss 1.6889 | Test Loss 0.002 | Test Error 48.85%\n",
            "Train Loss 0.150\n",
            "Train Loss 1.534\n",
            "Train Loss 1.659\n",
            "Train Loss 1.576\n",
            "Epoch  14 | Time   156s | Train Loss 1.6140 | Test Loss 0.002 | Test Error 49.29%\n",
            "Train Loss 0.190\n",
            "Train Loss 1.566\n",
            "Train Loss 1.507\n",
            "Train Loss 1.606\n",
            "Epoch  15 | Time   159s | Train Loss 1.6092 | Test Loss 0.002 | Test Error 45.93%\n",
            "Train Loss 0.171\n",
            "Train Loss 1.496\n",
            "Train Loss 1.584\n",
            "Train Loss 1.663\n",
            "Epoch  16 | Time   157s | Train Loss 1.5166 | Test Loss 0.002 | Test Error 46.50%\n",
            "Train Loss 0.149\n",
            "Train Loss 1.534\n",
            "Train Loss 1.478\n",
            "Train Loss 1.531\n",
            "Epoch  17 | Time   159s | Train Loss 1.5835 | Test Loss 0.002 | Test Error 48.77%\n",
            "Train Loss 0.149\n",
            "Train Loss 1.483\n",
            "Train Loss 1.544\n",
            "Train Loss 1.512\n",
            "Epoch  18 | Time   157s | Train Loss 1.5230 | Test Loss 0.002 | Test Error 44.84%\n",
            "Train Loss 0.142\n",
            "Train Loss 1.422\n",
            "Train Loss 1.508\n",
            "Train Loss 1.447\n",
            "Epoch  19 | Time   156s | Train Loss 1.4582 | Test Loss 0.002 | Test Error 48.44%\n",
            "Train Loss 0.154\n",
            "Train Loss 1.388\n",
            "Train Loss 1.365\n",
            "Train Loss 1.435\n",
            "Epoch  20 | Time   154s | Train Loss 1.4226 | Test Loss 0.002 | Test Error 46.91%\n",
            "Train Loss 0.102\n",
            "Train Loss 1.428\n",
            "Train Loss 1.396\n",
            "Train Loss 1.401\n",
            "Epoch  21 | Time   155s | Train Loss 1.4138 | Test Loss 0.002 | Test Error 43.02%\n",
            "Train Loss 0.100\n",
            "Train Loss 1.331\n",
            "Train Loss 1.422\n",
            "Train Loss 1.424\n",
            "Epoch  22 | Time   156s | Train Loss 1.4106 | Test Loss 0.002 | Test Error 44.72%\n",
            "Train Loss 0.138\n",
            "Train Loss 1.317\n",
            "Train Loss 1.329\n",
            "Train Loss 1.320\n",
            "Epoch  23 | Time   155s | Train Loss 1.3457 | Test Loss 0.002 | Test Error 41.17%\n",
            "Train Loss 0.138\n",
            "Train Loss 1.240\n",
            "Train Loss 1.266\n",
            "Train Loss 1.293\n",
            "Epoch  24 | Time   154s | Train Loss 1.3111 | Test Loss 0.001 | Test Error 41.22%\n",
            "Train Loss 0.143\n",
            "Train Loss 1.244\n",
            "Train Loss 1.292\n",
            "Train Loss 1.259\n",
            "Epoch  25 | Time   155s | Train Loss 1.3047 | Test Loss 0.002 | Test Error 43.29%\n",
            "Train Loss 0.114\n",
            "Train Loss 1.188\n",
            "Train Loss 1.308\n",
            "Train Loss 1.214\n",
            "Epoch  26 | Time   155s | Train Loss 1.2631 | Test Loss 0.002 | Test Error 42.95%\n",
            "Train Loss 0.095\n",
            "Train Loss 1.155\n",
            "Train Loss 1.252\n",
            "Train Loss 1.210\n",
            "Epoch  27 | Time   156s | Train Loss 1.2395 | Test Loss 0.001 | Test Error 39.39%\n",
            "Train Loss 0.120\n",
            "Train Loss 1.148\n",
            "Train Loss 1.161\n",
            "Train Loss 1.225\n",
            "Epoch  28 | Time   154s | Train Loss 1.1879 | Test Loss 0.001 | Test Error 38.82%\n",
            "Train Loss 0.112\n",
            "Train Loss 1.123\n",
            "Train Loss 1.125\n",
            "Train Loss 1.201\n",
            "Epoch  29 | Time   155s | Train Loss 1.1121 | Test Loss 0.001 | Test Error 38.19%\n",
            "Train Loss 0.097\n",
            "Train Loss 1.082\n",
            "Train Loss 1.078\n",
            "Train Loss 1.102\n",
            "Epoch  30 | Time   155s | Train Loss 1.1131 | Test Loss 0.001 | Test Error 37.37%\n",
            "Train Loss 0.102\n",
            "Train Loss 1.051\n",
            "Train Loss 1.019\n",
            "Train Loss 1.088\n",
            "Epoch  31 | Time   154s | Train Loss 1.0666 | Test Loss 0.001 | Test Error 36.08%\n",
            "Train Loss 0.086\n",
            "Train Loss 1.021\n",
            "Train Loss 1.013\n",
            "Train Loss 1.044\n",
            "Epoch  32 | Time   153s | Train Loss 1.0008 | Test Loss 0.001 | Test Error 35.65%\n",
            "Train Loss 0.122\n",
            "Train Loss 0.963\n",
            "Train Loss 0.974\n",
            "Train Loss 1.005\n",
            "Epoch  33 | Time   155s | Train Loss 1.0357 | Test Loss 0.001 | Test Error 34.36%\n",
            "Train Loss 0.097\n",
            "Train Loss 0.897\n",
            "Train Loss 0.942\n",
            "Train Loss 0.958\n",
            "Epoch  34 | Time   155s | Train Loss 0.9860 | Test Loss 0.001 | Test Error 35.06%\n",
            "Train Loss 0.088\n",
            "Train Loss 0.931\n",
            "Train Loss 0.927\n",
            "Train Loss 0.902\n",
            "Epoch  35 | Time   154s | Train Loss 0.8690 | Test Loss 0.001 | Test Error 31.98%\n",
            "Train Loss 0.096\n",
            "Train Loss 0.782\n",
            "Train Loss 0.839\n",
            "Train Loss 0.831\n",
            "Epoch  36 | Time   153s | Train Loss 0.8521 | Test Loss 0.001 | Test Error 32.05%\n",
            "Train Loss 0.082\n",
            "Train Loss 0.764\n",
            "Train Loss 0.806\n",
            "Train Loss 0.849\n",
            "Epoch  37 | Time   152s | Train Loss 0.8225 | Test Loss 0.001 | Test Error 32.23%\n",
            "Train Loss 0.077\n",
            "Train Loss 0.739\n",
            "Train Loss 0.777\n",
            "Train Loss 0.770\n",
            "Epoch  38 | Time   156s | Train Loss 0.7443 | Test Loss 0.001 | Test Error 31.29%\n",
            "Train Loss 0.067\n",
            "Train Loss 0.726\n",
            "Train Loss 0.732\n",
            "Train Loss 0.752\n",
            "Epoch  39 | Time   156s | Train Loss 0.7255 | Test Loss 0.001 | Test Error 30.62%\n",
            "Train Loss 0.057\n",
            "Train Loss 0.701\n",
            "Train Loss 0.700\n",
            "Train Loss 0.654\n",
            "Epoch  40 | Time   156s | Train Loss 0.6776 | Test Loss 0.001 | Test Error 29.49%\n",
            "Train Loss 0.062\n",
            "Train Loss 0.654\n",
            "Train Loss 0.597\n",
            "Train Loss 0.658\n",
            "Epoch  41 | Time   155s | Train Loss 0.6597 | Test Loss 0.001 | Test Error 27.99%\n",
            "Train Loss 0.059\n",
            "Train Loss 0.536\n",
            "Train Loss 0.560\n",
            "Train Loss 0.601\n",
            "Epoch  42 | Time   154s | Train Loss 0.5971 | Test Loss 0.001 | Test Error 26.84%\n",
            "Train Loss 0.051\n",
            "Train Loss 0.530\n",
            "Train Loss 0.523\n",
            "Train Loss 0.532\n",
            "Epoch  43 | Time   160s | Train Loss 0.5591 | Test Loss 0.001 | Test Error 27.03%\n",
            "Train Loss 0.056\n",
            "Train Loss 0.451\n",
            "Train Loss 0.491\n",
            "Train Loss 0.520\n",
            "Epoch  44 | Time   158s | Train Loss 0.4861 | Test Loss 0.001 | Test Error 26.55%\n",
            "Train Loss 0.043\n",
            "Train Loss 0.461\n",
            "Train Loss 0.439\n",
            "Train Loss 0.433\n",
            "Epoch  45 | Time   158s | Train Loss 0.4682 | Test Loss 0.001 | Test Error 26.10%\n",
            "Train Loss 0.031\n",
            "Train Loss 0.413\n",
            "Train Loss 0.431\n",
            "Train Loss 0.405\n",
            "Epoch  46 | Time   157s | Train Loss 0.4116 | Test Loss 0.001 | Test Error 25.96%\n",
            "Train Loss 0.041\n",
            "Train Loss 0.385\n",
            "Train Loss 0.379\n",
            "Train Loss 0.408\n",
            "Epoch  47 | Time   159s | Train Loss 0.4086 | Test Loss 0.001 | Test Error 25.58%\n",
            "Train Loss 0.040\n",
            "Train Loss 0.362\n",
            "Train Loss 0.399\n",
            "Train Loss 0.417\n",
            "Epoch  48 | Time   157s | Train Loss 0.3755 | Test Loss 0.001 | Test Error 25.72%\n",
            "Train Loss 0.028\n",
            "Train Loss 0.368\n",
            "Train Loss 0.356\n",
            "Train Loss 0.388\n",
            "Epoch  49 | Time   156s | Train Loss 0.3731 | Test Loss 0.001 | Test Error 25.79%\n",
            "Train Loss 0.032\n",
            "Train Loss 0.386\n",
            "Train Loss 0.385\n",
            "Train Loss 0.354\n",
            "Epoch  50 | Time   157s | Train Loss 0.3513 | Test Loss 0.001 | Test Error 25.56%\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(args.save):\n",
        "    os.makedirs(args.save)\n",
        "\n",
        "log_path = os.path.join(args.save, f'{args.dataset}_{args.model}_training_log.csv')\n",
        "with open(log_path, 'w') as f:\n",
        "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
        "\n",
        "print(f'Starting training from epoch {start_epoch + 1}')\n",
        "for epoch in range(start_epoch, args.epochs):\n",
        "    begin_time = time.time()\n",
        "\n",
        "    train_loss_ema = train(net, train_loader, optimizer, scheduler)\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "\n",
        "    is_best = test_acc > best_acc\n",
        "    best_acc = max(test_acc, best_acc)\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'dataset': args.dataset,\n",
        "        'model': args.model,\n",
        "        'state_dict': net.state_dict(),\n",
        "        'best_acc': best_acc,\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "    save_path = os.path.join(args.save, 'checkpoint.pth.tar')\n",
        "    torch.save(checkpoint, save_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(save_path, os.path.join(args.save, 'model_best.pth.tar'))\n",
        "\n",
        "    with open(log_path, 'a') as f:\n",
        "        f.write(f'{epoch+1:03d},{int(time.time() - begin_time):05d},{train_loss_ema:.6f},{test_loss:.5f},{100 - 100. * test_acc:.2f}\\n')\n",
        "\n",
        "    print(f'Epoch {epoch+1:3d} | Time {int(time.time() - begin_time):5d}s | '\n",
        "          f'Train Loss {train_loss_ema:.4f} | Test Loss {test_loss:.3f} | '\n",
        "          f'Test Error {100 - 100. * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAup3MSKmayk",
        "outputId": "c06f52fb-1097-4dee-927b-dad3e182a11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean\n",
            "\tTest Loss 0.001 | Test Accuracy 74.44%\n"
          ]
        }
      ],
      "source": [
        "if args.evaluate:\n",
        "    test_loss, test_acc = test(net, test_loader)\n",
        "    print(f'Clean\\n\\tTest Loss {test_loss:.3f} | Test Accuracy {test_acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4ZAmlrrStRTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9866f85d-137e-407b-d983-6bc7579edd8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gaussian_noise\n",
            "\tTest Loss 0.003 | Test Error 57.310\n",
            "shot_noise\n",
            "\tTest Loss 0.002 | Test Error 49.702\n",
            "impulse_noise\n",
            "\tTest Loss 0.002 | Test Error 46.224\n",
            "defocus_blur\n",
            "\tTest Loss 0.001 | Test Error 29.158\n",
            "glass_blur\n",
            "\tTest Loss 0.003 | Test Error 63.708\n",
            "motion_blur\n",
            "\tTest Loss 0.001 | Test Error 34.154\n",
            "zoom_blur\n",
            "\tTest Loss 0.001 | Test Error 32.562\n",
            "snow\n",
            "\tTest Loss 0.002 | Test Error 41.130\n",
            "frost\n",
            "\tTest Loss 0.002 | Test Error 44.958\n",
            "fog\n",
            "\tTest Loss 0.002 | Test Error 35.568\n",
            "brightness\n",
            "\tTest Loss 0.001 | Test Error 28.774\n",
            "contrast\n",
            "\tTest Loss 0.002 | Test Error 40.604\n",
            "elastic_transform\n",
            "\tTest Loss 0.002 | Test Error 36.722\n",
            "pixelate\n",
            "\tTest Loss 0.002 | Test Error 42.072\n",
            "jpeg_compression\n",
            "\tTest Loss 0.002 | Test Error 46.818\n",
            "Mean Corruption Error: 41.96%\n"
          ]
        }
      ],
      "source": [
        "test_c_acc = test_c(net, test_data, base_c_path)\n",
        "print(f'Mean Corruption Error: {100 - 100. * test_c_acc:.2f}%')\n",
        "\n",
        "with open(log_path, 'a') as f:\n",
        "    f.write(f'{args.epochs + 1:03d},00000,0.000000,0.00000,{100 - 100 * test_c_acc:.2f}\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}